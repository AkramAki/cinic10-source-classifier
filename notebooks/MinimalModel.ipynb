{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e558ac9-dcfb-4ff1-ab7f-3ff3adde7f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-25 12:21:05.974282: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import layers, models\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "import multiprocessing\n",
    "from pathlib import Path\n",
    "from IPython.display import Image\n",
    "\n",
    "from utils.DomainImageGenerator import DomainImageGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3761d1-2148-433d-9e03-fab17489597d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Dataset as Generators so not all images are loaded into ram at the same time. The generator class loads the needed images per batch\n",
    "cpu_count = multiprocessing.cpu_count()\n",
    "njobs = int(cpu_count * 0.9) # Just set to use some percent of cpus\n",
    "max_queue_size = 15\n",
    "use_multiprocessing = True\n",
    "\n",
    "train_gen = DomainImageGenerator(\"prepared/train.csv\", batch_size=64, img_size=(32, 32), shuffle=True, n_jobs=njobs, use_multiprocessing=use_multiprocessing, max_queue_size=max_queue_size) # \"batch_size=64, img_size=(32, 32), shuffle=True]\" are the default values\n",
    "val_gen = DomainImageGenerator(\"prepared/valid.csv\", batch_size=64, n_jobs=njobs, use_multiprocessing=use_multiprocessing, max_queue_size=max_queue_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab32aaa7-dee8-4e4e-a961-4ee1eaf10b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the Dataset without a generator (not recommended)\n",
    "### x contains an array with dimensions (n_samples, 32, 32, 3) where 32x32 is the image size and 3 is for the different color channels\n",
    "### The values are scaled between 0 and 1\n",
    "### y contains an array with dimensions (n_samples, 1) where the labels are given as either 0 or 1\n",
    "\n",
    "# from utils.utils_ModelTraining import load_data_all_splits, prepare_dataset\n",
    "# train_df, val_df, test_df = load_data_all_splits()\n",
    "\n",
    "# print(\"Train Data\")\n",
    "# x_train, y_train = prepare_dataset(train_df)\n",
    "# print(\"Validation Data\")\n",
    "# x_val, y_val = prepare_dataset(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8279081c-8278-4a73-bf88-0e8ece9154f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Input(shape=(32, 32, 3)),\n",
    "    layers.Conv2D(2, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    #layers.Conv2D(5, (3, 3), activation='relu'),\n",
    "    #layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    #layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')  # binary classification\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cd5707-b68e-4d7e-adfb-982c6575a5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5067b531-03d7-4885-9f80-e15dbad74e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"build\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"build/MinimlModel\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "plot_model(model, to_file='build/MinimlModel/Model.png', show_shapes=True, show_layer_names=True)\n",
    "Image('build/MinimlModel/Model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2398cfe8-4ac2-4029-91d2-4a5b973514bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=40,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c028fd3e-fa40-48ec-9d1c-1641a74230be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42730ff5-3ef5-4b18-afa4-4a0ea151e132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'validation'], loc='upper right')\n",
    "plt.savefig(\"build/MinimlModel/Loss.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ce6de1-020c-4905-99b0-b28b01ea3506",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../models/MinimlModel.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
